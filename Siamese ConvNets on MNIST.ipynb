{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and test data from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (60000, 28, 28)\n",
      "Train Y: (60000,)\n",
      "Test X: (10000, 28, 28)\n",
      "Test Y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Train X:', x_train.shape)\n",
    "print('Train Y:', y_train.shape)\n",
    "print('Test X:', x_test.shape)\n",
    "print('Test Y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the inputs compatible with ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the new shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (60000, 28, 28, 1)\n",
      "Train Y: (60000,)\n",
      "Test X: (10000, 28, 28, 1)\n",
      "Test Y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Train X:', x_train.shape)\n",
    "print('Train Y:', y_train.shape)\n",
    "print('Test X:', x_test.shape)\n",
    "print('Test Y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes an input and output (target classes) array and generated a number of pairs from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "def GeneratePairs(x, y, num_pairs):\n",
    "    assert x.shape[0]==y.shape[0]\n",
    "    num_samples = x.shape[0]\n",
    "    num_classes = y.max() + 1 # in the case of mnist, it is 10\n",
    "    \n",
    "    #separate x samples based on the y value, this makes it easier to generate an equal number of positive\n",
    "    # and negative pairs\n",
    "    separated = [[] for c in range(num_classes)]\n",
    "    for i in range(num_samples):\n",
    "        separated[y[i]].append(x[i])\n",
    "    \n",
    "    #left input\n",
    "    l = np.empty(shape=(num_pairs, x.shape[1], x.shape[2], x.shape[3]), dtype=np.float32)\n",
    "    #right input\n",
    "    r = np.empty(shape=(num_pairs, x.shape[1], x.shape[2], x.shape[3]), dtype=np.float32)\n",
    "    #output (class: 0 or 1)\n",
    "    o = np.empty(shape=(num_pairs, 1), dtype=np.float32)\n",
    "    \n",
    "    for i in tqdm(range(num_pairs)):\n",
    "        if i%2==0: #negative pair\n",
    "            #randomly pick two differnt classes (y values)\n",
    "            y_l = randint(0, num_classes-1)\n",
    "            y_r = (y_l + randint(1, num_classes-2)) % num_classes # make sure y_l != y_r\n",
    "            #for each class pick a random sample\n",
    "            x_l = randint(0, len(separated[y_l])-1)\n",
    "            x_r = randint(0, len(separated[y_r])-1)\n",
    "            #add the random pair to the data arrays\n",
    "            l[i, :, :, :] = separated[y_l][x_l][:, :, :]\n",
    "            r[i, :, :, :] = separated[y_r][x_r][:, :, :]\n",
    "            o[i, 0] = 0\n",
    "        else: #positive pair\n",
    "            #randomly pick a class (y value)\n",
    "            c = randint(0, num_classes-1)\n",
    "            #pick two random samples\n",
    "            num_x = len(separated[c])\n",
    "            x_l = randint(0, num_x-1)\n",
    "            x_r = (x_l + randint(1, num_x-2)) % num_x # make sure x_l != x_r\n",
    "            #add the random pair to the data arrays\n",
    "            l[i, :, :, :] = separated[c][x_l][:, :, :]\n",
    "            r[i, :, :, :] = separated[c][x_r][:, :, :]\n",
    "            o[i, 0] = 1\n",
    "    return (l, r, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the previous function to generate training as test pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 600000/600000 [00:11<00:00, 51808.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 100000/100000 [00:02<00:00, 34960.79it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_l, train_r, train_y) = GeneratePairs(x_train, y_train, 600000)\n",
    "(test_l, test_r, test_y) = GeneratePairs(x_test, y_test, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will create the Siamese ConvNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"Siamese_CNN\", inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "import keras.backend as K\n",
    "\n",
    "in_shape = (28, 28, 1)\n",
    "\n",
    "#Feature Extraction ConvNet\n",
    "ConvNet = Sequential(name='Feature_CNN')\n",
    "ConvNet.add(Conv2D(16, kernel_size=3, activation='relu', padding='same', input_shape=in_shape))\n",
    "ConvNet.add(MaxPooling2D())\n",
    "ConvNet.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "ConvNet.add(MaxPooling2D())\n",
    "ConvNet.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "ConvNet.add(Flatten())\n",
    "\n",
    "#Siamese ConvNet Creation using Keras Functional API\n",
    "#Left Input\n",
    "input_l = Input(shape=in_shape)\n",
    "#Right Input\n",
    "input_r = Input(shape=in_shape)\n",
    "#Left Feature-Vector\n",
    "encoded_l = ConvNet(input_l)\n",
    "#Right Feature-Vector\n",
    "encoded_r = ConvNet(input_r)\n",
    "#L1 Lambda Layer\n",
    "#  Merge function\n",
    "def L1_Merge(x):\n",
    "    return K.abs(x[0]-x[1])\n",
    "#  Shape function\n",
    "def L1_Shape(s):\n",
    "    return s[0]\n",
    "#  Combine the two feature-vectors using a Lambda Layer\n",
    "merged = Lambda(function=L1_Merge, output_shape=L1_Shape)([encoded_l, encoded_r])\n",
    "#Classification\n",
    "prediction = Dense(1, activation='sigmoid')(merged)\n",
    "#Create The Siamese ConvVet model\n",
    "SiameseNet = Model(name='Siamese_CNN', input=[input_l, input_r], output=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Extraction ConvNet</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Feature_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "=================================================================\n",
      "Total params: 23,296\n",
      "Trainable params: 23,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ConvNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Siamese Convnet</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_CNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feature_CNN (Sequential)        (None, 3136)         23296       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 3136)         0           Feature_CNN[1][0]                \n",
      "                                                                 Feature_CNN[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            3137        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 26,433\n",
      "Trainable params: 26,433\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SiameseNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compile the model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "SiameseNet.compile(optimizer=SGD(0.05), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train the model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abdal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/100\n",
      " - 59s - loss: 0.4401 - acc: 0.7842\n",
      "Epoch 2/100\n",
      " - 31s - loss: 0.1802 - acc: 0.9305\n",
      "Epoch 3/100\n",
      " - 31s - loss: 0.1250 - acc: 0.9533\n",
      "Epoch 4/100\n",
      " - 31s - loss: 0.1026 - acc: 0.9620\n",
      "Epoch 5/100\n",
      " - 32s - loss: 0.0888 - acc: 0.9673\n",
      "Epoch 6/100\n",
      " - 33s - loss: 0.0798 - acc: 0.9707\n",
      "Epoch 7/100\n",
      " - 33s - loss: 0.0726 - acc: 0.9733\n",
      "Epoch 8/100\n",
      " - 36s - loss: 0.0665 - acc: 0.9760\n",
      "Epoch 9/100\n",
      " - 36s - loss: 0.0620 - acc: 0.9775\n",
      "Epoch 10/100\n",
      " - 39s - loss: 0.0577 - acc: 0.9792\n",
      "Epoch 11/100\n",
      " - 40s - loss: 0.0542 - acc: 0.9805\n",
      "Epoch 12/100\n",
      " - 40s - loss: 0.0510 - acc: 0.9816\n",
      "Epoch 13/100\n",
      " - 45s - loss: 0.0485 - acc: 0.9826\n",
      "Epoch 14/100\n",
      " - 46s - loss: 0.0461 - acc: 0.9835\n",
      "Epoch 15/100\n",
      " - 49s - loss: 0.0439 - acc: 0.9843\n",
      "Epoch 16/100\n",
      " - 48s - loss: 0.0419 - acc: 0.9850\n",
      "Epoch 17/100\n",
      " - 48s - loss: 0.0400 - acc: 0.9859\n",
      "Epoch 18/100\n",
      " - 48s - loss: 0.0384 - acc: 0.9863\n",
      "Epoch 19/100\n",
      " - 52s - loss: 0.0368 - acc: 0.9870\n",
      "Epoch 20/100\n",
      " - 52s - loss: 0.0355 - acc: 0.9876\n",
      "Epoch 21/100\n",
      " - 50s - loss: 0.0340 - acc: 0.9881\n",
      "Epoch 22/100\n",
      " - 54s - loss: 0.0329 - acc: 0.9885\n",
      "Epoch 23/100\n",
      " - 52s - loss: 0.0317 - acc: 0.9888\n",
      "Epoch 24/100\n",
      " - 52s - loss: 0.0305 - acc: 0.9892\n",
      "Epoch 25/100\n",
      " - 51s - loss: 0.0295 - acc: 0.9896\n",
      "Epoch 26/100\n",
      " - 54s - loss: 0.0284 - acc: 0.9900\n",
      "Epoch 27/100\n",
      " - 55s - loss: 0.0275 - acc: 0.9904\n",
      "Epoch 28/100\n",
      " - 54s - loss: 0.0266 - acc: 0.9907\n",
      "Epoch 29/100\n",
      " - 56s - loss: 0.0258 - acc: 0.9912\n",
      "Epoch 30/100\n",
      " - 55s - loss: 0.0250 - acc: 0.9913\n",
      "Epoch 31/100\n",
      " - 63s - loss: 0.0243 - acc: 0.9915\n",
      "Epoch 32/100\n",
      " - 55s - loss: 0.0234 - acc: 0.9918\n",
      "Epoch 33/100\n",
      " - 57s - loss: 0.0229 - acc: 0.9921\n",
      "Epoch 34/100\n",
      " - 53s - loss: 0.0223 - acc: 0.9922\n",
      "Epoch 35/100\n",
      " - 55s - loss: 0.0214 - acc: 0.9926\n",
      "Epoch 36/100\n",
      " - 60s - loss: 0.0210 - acc: 0.9928\n",
      "Epoch 37/100\n",
      " - 57s - loss: 0.0203 - acc: 0.9930\n",
      "Epoch 38/100\n",
      " - 53s - loss: 0.0199 - acc: 0.9931\n",
      "Epoch 39/100\n",
      " - 59s - loss: 0.0192 - acc: 0.9933\n",
      "Epoch 40/100\n",
      " - 55s - loss: 0.0190 - acc: 0.9934\n",
      "Epoch 41/100\n",
      " - 56s - loss: 0.0186 - acc: 0.9935\n",
      "Epoch 42/100\n",
      " - 53s - loss: 0.0178 - acc: 0.9939\n",
      "Epoch 43/100\n",
      " - 55s - loss: 0.0173 - acc: 0.9940\n",
      "Epoch 44/100\n",
      " - 54s - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 45/100\n",
      " - 54s - loss: 0.0163 - acc: 0.9944\n",
      "Epoch 46/100\n",
      " - 56s - loss: 0.0159 - acc: 0.9945\n",
      "Epoch 47/100\n",
      " - 55s - loss: 0.0156 - acc: 0.9947\n",
      "Epoch 48/100\n",
      " - 56s - loss: 0.0151 - acc: 0.9949\n",
      "Epoch 49/100\n",
      " - 56s - loss: 0.0148 - acc: 0.9949\n",
      "Epoch 50/100\n",
      " - 57s - loss: 0.0144 - acc: 0.9951\n",
      "Epoch 51/100\n",
      " - 54s - loss: 0.0139 - acc: 0.9952\n",
      "Epoch 52/100\n",
      " - 56s - loss: 0.0137 - acc: 0.9953\n",
      "Epoch 53/100\n",
      " - 56s - loss: 0.0133 - acc: 0.9953\n",
      "Epoch 54/100\n",
      " - 52s - loss: 0.0131 - acc: 0.9955\n",
      "Epoch 55/100\n",
      " - 52s - loss: 0.0126 - acc: 0.9957\n",
      "Epoch 56/100\n",
      " - 53s - loss: 0.0124 - acc: 0.9957\n",
      "Epoch 57/100\n",
      " - 51s - loss: 0.0119 - acc: 0.9960\n",
      "Epoch 58/100\n",
      " - 51s - loss: 0.0118 - acc: 0.9959\n",
      "Epoch 59/100\n",
      " - 49s - loss: 0.0115 - acc: 0.9960\n",
      "Epoch 60/100\n",
      " - 55s - loss: 0.0112 - acc: 0.9962\n",
      "Epoch 61/100\n",
      " - 52s - loss: 0.0108 - acc: 0.9963\n",
      "Epoch 62/100\n",
      " - 48s - loss: 0.0106 - acc: 0.9965\n",
      "Epoch 63/100\n",
      " - 48s - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 64/100\n",
      " - 48s - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 65/100\n",
      " - 48s - loss: 0.0098 - acc: 0.9967\n",
      "Epoch 66/100\n",
      " - 48s - loss: 0.0096 - acc: 0.9967\n",
      "Epoch 67/100\n",
      " - 48s - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 68/100\n",
      " - 48s - loss: 0.0091 - acc: 0.9969\n",
      "Epoch 69/100\n",
      " - 48s - loss: 0.0090 - acc: 0.9970\n",
      "Epoch 70/100\n",
      " - 48s - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 71/100\n",
      " - 48s - loss: 0.0084 - acc: 0.9971\n",
      "Epoch 72/100\n",
      " - 48s - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 73/100\n",
      " - 48s - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 74/100\n",
      " - 48s - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 75/100\n",
      " - 48s - loss: 0.0074 - acc: 0.9976\n",
      "Epoch 76/100\n",
      " - 48s - loss: 0.0074 - acc: 0.9976\n",
      "Epoch 77/100\n",
      " - 48s - loss: 0.0072 - acc: 0.9976\n",
      "Epoch 78/100\n",
      " - 48s - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 79/100\n",
      " - 48s - loss: 0.0067 - acc: 0.9978\n",
      "Epoch 80/100\n",
      " - 48s - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 81/100\n",
      " - 48s - loss: 0.0063 - acc: 0.9979\n",
      "Epoch 82/100\n",
      " - 48s - loss: 0.0063 - acc: 0.9979\n",
      "Epoch 83/100\n",
      " - 48s - loss: 0.0060 - acc: 0.9981\n",
      "Epoch 84/100\n",
      " - 48s - loss: 0.0059 - acc: 0.9981\n",
      "Epoch 85/100\n",
      " - 48s - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 86/100\n",
      " - 48s - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 87/100\n",
      " - 48s - loss: 0.0052 - acc: 0.9984\n",
      "Epoch 88/100\n",
      " - 48s - loss: 0.0052 - acc: 0.9984\n",
      "Epoch 89/100\n",
      " - 48s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 90/100\n",
      " - 48s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 91/100\n",
      " - 48s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 92/100\n",
      " - 48s - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 93/100\n",
      " - 48s - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 94/100\n",
      " - 48s - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 95/100\n",
      " - 48s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 96/100\n",
      " - 48s - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 97/100\n",
      " - 52s - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 98/100\n",
      " - 53s - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 99/100\n",
      " - 45s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 100/100\n",
      " - 56s - loss: 0.0034 - acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b323572ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiameseNet.fit([train_l, train_r], train_y, batch_size=500, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluate the trained model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08496359100975695, 0.98333]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiameseNet.evaluate([test_l, test_r], test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
